{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pose Classification Prediction\n",
    "\n",
    "This notebook provides functionality to classify poses as correct or incorrect using our trained GCN model.\n",
    "\n",
    "## Input Requirements\n",
    "- **Keypoints**: Array/list of shape (17, 2) containing x,y coordinates in COCO format\n",
    "- **Visibility** (optional): Array/list of shape (17) containing visibility flags\n",
    "  - 0: not labeled\n",
    "  - 1: labeled but not visible\n",
    "  - 2: labeled and visible (default)\n",
    "\n",
    "### COCO Keypoint Order\n",
    "1. nose\n",
    "2. left_eye\n",
    "3. right_eye\n",
    "4. left_ear\n",
    "5. right_ear\n",
    "6. left_shoulder\n",
    "7. right_shoulder\n",
    "8. left_elbow\n",
    "9. right_elbow\n",
    "10. left_wrist\n",
    "11. right_wrist\n",
    "12. left_hip\n",
    "13. right_hip\n",
    "14. left_knee\n",
    "15. right_knee\n",
    "16. left_ankle\n",
    "17. right_ankle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "from sklearn.metrics import classification_report\n",
    "import os\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import our modules\n",
    "import sys\n",
    "sys.path.append('src')\n",
    "from data_processing import load_dataset, PoseDataset\n",
    "from gcn_model import PoseGCN\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trained_model(model_path, device):\n",
    "    \"\"\"Load the trained model from a checkpoint file.\"\"\"\n",
    "    # Initialize model\n",
    "    model = PoseGCN(num_node_features=2).to(device)\n",
    "    \n",
    "    # Load state dict\n",
    "    state_dict = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(state_dict)\n",
    "    print(\"Model loaded successfully\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "def prepare_single_pose_input(keypoints, visibility=None):\n",
    "    \"\"\"Prepare a single pose input for prediction.\"\"\"\n",
    "    # Convert input to numpy array if it's a list\n",
    "    keypoints = np.array(keypoints)\n",
    "    \n",
    "    # Validate input shape\n",
    "    if keypoints.shape != (17, 2):\n",
    "        raise ValueError(f\"Expected keypoints shape (17, 2), got {keypoints.shape}\")\n",
    "    \n",
    "    # Handle visibility\n",
    "    if visibility is None:\n",
    "        visibility = np.full(17, 2)  # All keypoints visible\n",
    "    else:\n",
    "        visibility = np.array(visibility)\n",
    "        if visibility.shape != (17,):\n",
    "            raise ValueError(f\"Expected visibility shape (17,), got {visibility.shape}\")\n",
    "    \n",
    "    # Convert to torch tensors\n",
    "    x = torch.tensor(keypoints, dtype=torch.float)\n",
    "    v = torch.tensor(visibility, dtype=torch.float).view(-1, 1)\n",
    "    \n",
    "    # Create edge index for the pose graph\n",
    "    edge_index = torch.tensor([\n",
    "        [0, 1], [1, 0],  # nose - left eye\n",
    "        [0, 2], [2, 0],  # nose - right eye\n",
    "        [1, 3], [3, 1],  # left eye - left ear\n",
    "        [2, 4], [4, 2],  # right eye - right ear\n",
    "        [5, 6], [6, 5],  # left shoulder - right shoulder\n",
    "        [5, 7], [7, 5],  # left shoulder - left elbow\n",
    "        [6, 8], [8, 6],  # right shoulder - right elbow\n",
    "        [7, 9], [9, 7],  # left elbow - left wrist\n",
    "        [8, 10], [10, 8],  # right elbow - right wrist\n",
    "        [5, 11], [11, 5],  # left shoulder - left hip\n",
    "        [6, 12], [12, 6],  # right shoulder - right hip\n",
    "        [11, 12], [12, 11],  # left hip - right hip\n",
    "        [11, 13], [13, 11],  # left hip - left knee\n",
    "        [12, 14], [14, 12],  # right hip - right knee\n",
    "        [13, 15], [15, 13],  # left knee - left ankle\n",
    "        [14, 16], [16, 14],  # right knee - right ankle\n",
    "    ], dtype=torch.long)\n",
    "    \n",
    "    # Create PyG Data object\n",
    "    data = Data(x=x, edge_index=edge_index.t().contiguous(), vis=v)\n",
    "    return data\n",
    "\n",
    "def predict_single(model, data, device):\n",
    "    \"\"\"Make prediction for a single pose.\"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        data = data.to(device)\n",
    "        output = model(data)\n",
    "        pred = output.max(dim=1)[1]\n",
    "        prob = torch.exp(output)  # Convert log probabilities to probabilities\n",
    "    return pred.item(), prob[0].cpu().numpy()\n",
    "\n",
    "def predict_pose(keypoints, visibility=None):\n",
    "    \"\"\"Predict whether a pose is correct or incorrect.\"\"\"\n",
    "    # Set device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # Load the trained model\n",
    "    model_path = 'models/model-1/best_model.pth'\n",
    "    if not os.path.exists(model_path):\n",
    "        raise FileNotFoundError(f\"Model file not found at {model_path}\")\n",
    "    \n",
    "    model = load_trained_model(model_path, device)\n",
    "    \n",
    "    # Prepare input data\n",
    "    data = prepare_single_pose_input(keypoints, visibility)\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction, probabilities = predict_single(model, data, device)\n",
    "    \n",
    "    # Convert prediction to class name and get confidence\n",
    "    pred_class = \"Correct\" if prediction == 1 else \"Incorrect\"\n",
    "    confidence = max(probabilities)\n",
    "    \n",
    "    return pred_class, confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Test on Sample Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Loading annotations from annotations_v1\n",
      "Loaded 102 annotations from annotations_v1\\correct_n2_3_7_100.json\n",
      "Number of images: 579\n",
      "Categories: ['human']\n",
      "Successfully processed 102 keypoint annotations\n",
      "Loaded 108 annotations from annotations_v1\\lumbar_3_7_dell_111.json\n",
      "Number of images: 464\n",
      "Categories: ['human']\n",
      "Successfully processed 108 keypoint annotations\n",
      "Loaded 102 correct poses and 108 incorrect poses\n",
      "Total dataset size: 210 samples\n",
      "\n",
      "Loaded 42 test samples\n"
     ]
    }
   ],
   "source": [
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load test dataset\n",
    "_, test_dataset = load_dataset(\n",
    "    root_dir='data_v1',\n",
    "    annotation_dir='annotations_v1'\n",
    ")\n",
    "\n",
    "print(f\"\\nLoaded {len(test_dataset)} test samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Incorrect       0.39      0.61      0.48        18\n",
      "     Correct       0.50      0.29      0.37        24\n",
      "\n",
      "    accuracy                           0.43        42\n",
      "   macro avg       0.45      0.45      0.42        42\n",
      "weighted avg       0.45      0.43      0.42        42\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create data loader and make predictions\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "# Load model\n",
    "model = load_trained_model('models/model-1/best_model.pth', device)\n",
    "\n",
    "# Make predictions\n",
    "model.eval()\n",
    "predictions = []\n",
    "probabilities = []\n",
    "labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        data = data.to(device)\n",
    "        output = model(data)\n",
    "        pred = output.max(dim=1)[1]\n",
    "        prob = torch.exp(output)\n",
    "        \n",
    "        predictions.extend(pred.cpu().numpy())\n",
    "        probabilities.extend(prob.cpu().numpy())\n",
    "        labels.extend(data.y.cpu().numpy())\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(labels, predictions, target_names=['Incorrect', 'Correct']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Predict Single Pose\n",
    "\n",
    "Here's how to use the model to predict a single pose. Replace the example keypoints with your actual pose keypoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully\n",
      "Prediction: Correct\n",
      "Confidence: 69.50%\n"
     ]
    }
   ],
   "source": [
    "# Example keypoints (replace with your actual keypoints)\n",
    "example_keypoints = np.array([\n",
    "    [0.5, 0.5],  # nose\n",
    "    [0.45, 0.45],  # left_eye\n",
    "    [0.55, 0.45],  # right_eye\n",
    "    [0.4, 0.5],  # left_ear\n",
    "    [0.6, 0.5],  # right_ear\n",
    "    [0.3, 0.7],  # left_shoulder\n",
    "    [0.7, 0.7],  # right_shoulder\n",
    "    [0.2, 0.9],  # left_elbow\n",
    "    [0.8, 0.9],  # right_elbow\n",
    "    [0.1, 1.1],  # left_wrist\n",
    "    [0.9, 1.1],  # right_wrist\n",
    "    [0.4, 1.2],  # left_hip\n",
    "    [0.6, 1.2],  # right_hip\n",
    "    [0.35, 1.5],  # left_knee\n",
    "    [0.65, 1.5],  # right_knee\n",
    "    [0.3, 1.8],  # left_ankle\n",
    "    [0.7, 1.8],  # right_ankle\n",
    "])\n",
    "\n",
    "# Example visibility (all keypoints visible)\n",
    "example_visibility = np.ones(17) * 2\n",
    "\n",
    "# Make prediction\n",
    "pred_class, confidence = predict_pose(example_keypoints, example_visibility)\n",
    "\n",
    "print(f\"Prediction: {pred_class}\")\n",
    "print(f\"Confidence: {confidence:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Use for Your Own Poses\n",
    "\n",
    "To classify your own poses:\n",
    "\n",
    "1. Prepare your keypoints in COCO format (17 keypoints, each with x,y coordinates)\n",
    "2. Optionally prepare visibility flags for each keypoint\n",
    "3. Use the `predict_pose()` function as shown in Example 2 above\n",
    "\n",
    "Example code template:\n",
    "```python\n",
    "# Prepare your keypoints\n",
    "my_keypoints = np.array([\n",
    "    [x1, y1],  # nose\n",
    "    [x2, y2],  # left_eye\n",
    "    # ... add all 17 keypoints\n",
    "])\n",
    "\n",
    "# Optional: prepare visibility\n",
    "my_visibility = np.array([2, 2, 2, ...])  # 2 for visible, 1 for occluded, 0 for unlabeled\n",
    "\n",
    "# Make prediction\n",
    "prediction, confidence = predict_pose(my_keypoints, my_visibility)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
