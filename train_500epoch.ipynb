{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improved Human Pose Classification using GCN\n",
    "\n",
    "This notebook implements the enhanced training pipeline for classifying human poses using Graph Convolutional Networks (GCN) with the following improvements:\n",
    "\n",
    "1. Deeper GCN architecture with residual connections\n",
    "2. Data augmentation for better generalization\n",
    "3. Class weighting for balanced training\n",
    "4. Early stopping to prevent overfitting\n",
    "5. Learning rate scheduling for better convergence\n",
    "6. Regular checkpointing during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Import our modules\n",
    "import sys\n",
    "sys.path.append('src')\n",
    "from data_processing import load_dataset, PoseAugmentation\n",
    "from gcn_model import PoseGCN, DeepPoseGCN\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add early stopping utility\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation score doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=50, verbose=True, delta=0, path='checkpoint.pt'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last improvement.\n",
    "            verbose (bool): If True, prints a message for each validation improvement.\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_score_max = 0\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "\n",
    "    def __call__(self, val_score, model):\n",
    "        # Higher score is better (e.g., F1)\n",
    "        score = val_score\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_score, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_score, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_score, model):\n",
    "        '''Saves model when validation score improves.'''\n",
    "        if self.verbose:\n",
    "            print(f'Validation score improved ({self.val_score_max:.6f} --> {val_score:.6f}). Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_score_max = val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Data Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and verify data paths\n",
    "data_dir = os.path.join(os.getcwd(), 'data_v2')\n",
    "annotation_dir = os.path.join(os.getcwd(), 'annotations_v2')\n",
    "\n",
    "# Check if directories exist\n",
    "print(f\"Checking data directory: {data_dir}\")\n",
    "print(f\"Exists: {os.path.exists(data_dir)}\")\n",
    "\n",
    "print(f\"\\nChecking annotation directory: {annotation_dir}\")\n",
    "print(f\"Exists: {os.path.exists(annotation_dir)}\")\n",
    "\n",
    "# Check annotation files\n",
    "annotation_files = [\n",
    "    't5-sherul-300-195-correct.json',\n",
    "    'lumbar-K-1.1-160.json'\n",
    "]\n",
    "\n",
    "print(\"\\nChecking annotation files:\")\n",
    "for file in annotation_files:\n",
    "    file_path = os.path.join(annotation_dir, file)\n",
    "    print(f\"{file}: {'Exists' if os.path.exists(file_path) else 'Missing'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Training and Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, device, class_weights=None):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for data in tqdm(train_loader, desc='Training', leave=False):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        output = model(data)\n",
    "        \n",
    "        # Use weighted loss if class weights are provided\n",
    "        if class_weights is not None:\n",
    "            loss = torch.nn.functional.nll_loss(output, data.y, weight=class_weights)\n",
    "        else:\n",
    "            loss = torch.nn.functional.nll_loss(output, data.y)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            data = data.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.max(dim=1)[1]\n",
    "            \n",
    "            predictions.extend(pred.cpu().numpy())\n",
    "            labels.extend(data.y.cpu().numpy())\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels, predictions, average='binary'\n",
    "    )\n",
    "    \n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(train_losses, val_metrics, save_path='models/training_metrics.png'):\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))\n",
    "    \n",
    "    # Plot training loss\n",
    "    ax1.plot(train_losses, 'b-', label='Training Loss')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.grid(True)\n",
    "    ax1.legend()\n",
    "    \n",
    "    # Plot validation metrics\n",
    "    epochs = range(len(val_metrics['accuracy']))\n",
    "    ax2.plot(epochs, val_metrics['accuracy'], 'g-', label='Accuracy')\n",
    "    ax2.plot(epochs, val_metrics['precision'], 'r-', label='Precision')\n",
    "    ax2.plot(epochs, val_metrics['recall'], 'b-', label='Recall')\n",
    "    ax2.plot(epochs, val_metrics['f1'], 'y-', label='F1-Score')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Score')\n",
    "    ax2.grid(True)\n",
    "    ax2.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path)\n",
    "    plt.show()\n",
    "    print(f\"Saved training plot to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, train_loader, val_loader, optimizer, num_epochs=500, device='cpu', \n",
    "                       class_weights=None, early_stopping_patience=50, checkpoint_dir='models'):\n",
    "    best_f1 = 0\n",
    "    train_losses = []\n",
    "    val_metrics = {'accuracy': [], 'precision': [], 'recall': [], 'f1': []}\n",
    "    learning_rates = [optimizer.param_groups[0]['lr']]  # Track learning rates\n",
    "    \n",
    "    # Initialize early stopping\n",
    "    model_name = model.__class__.__name__\n",
    "    early_stopping = EarlyStopping(\n",
    "        patience=early_stopping_patience, \n",
    "        verbose=True, \n",
    "        path=f'{checkpoint_dir}/model_{model_name}_early_stop.pth'\n",
    "    )\n",
    "    \n",
    "    # Initialize learning rate scheduler\n",
    "    scheduler = ReduceLROnPlateau(\n",
    "        optimizer, mode='max', factor=0.5, patience=30, verbose=True\n",
    "    )\n",
    "    \n",
    "    # Create checkpoint directory if it doesn't exist\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    \n",
    "    epoch_checkpoints = [50, 100, 200, 300, 400]  # Save at these specific epochs\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Train\n",
    "        train_loss = train(model, train_loader, optimizer, device, class_weights)\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        # Evaluate\n",
    "        val_acc, val_prec, val_rec, val_f1 = evaluate(model, val_loader, device)\n",
    "        \n",
    "        # Store metrics\n",
    "        val_metrics['accuracy'].append(val_acc)\n",
    "        val_metrics['precision'].append(val_prec)\n",
    "        val_metrics['recall'].append(val_rec)\n",
    "        val_metrics['f1'].append(val_f1)\n",
    "        \n",
    "        # Print progress\n",
    "        print(f'Epoch {epoch+1:03d}:')\n",
    "        print(f'Train Loss: {train_loss:.4f}')\n",
    "        print(f'Val Accuracy: {val_acc:.4f}, Precision: {val_prec:.4f}, '\n",
    "              f'Recall: {val_rec:.4f}, F1: {val_f1:.4f}')\n",
    "        \n",
    "        # Update learning rate based on validation F1 score\n",
    "        scheduler.step(val_f1)\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        learning_rates.append(current_lr)  # Track learning rate changes\n",
    "        print(f'Current learning rate: {current_lr:.6f}')\n",
    "        \n",
    "        # Save best model whenever a new best F1 score is achieved\n",
    "        if val_f1 > best_f1:\n",
    "            best_f1 = val_f1\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_metrics': val_metrics,\n",
    "                'train_losses': train_losses,\n",
    "                'learning_rate': current_lr,\n",
    "                'learning_rates': learning_rates\n",
    "            }, f'{checkpoint_dir}/model_{model_name}_best.pth')\n",
    "            print(f\"Saved best model with F1: {val_f1:.4f}\")\n",
    "        \n",
    "        # Save checkpoint at specific epoch milestones\n",
    "        if (epoch + 1) in epoch_checkpoints:\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_metrics': val_metrics,\n",
    "                'train_losses': train_losses,\n",
    "                'learning_rate': current_lr,\n",
    "                'learning_rates': learning_rates\n",
    "            }, f'{checkpoint_dir}/model_{model_name}_epoch_{epoch+1}.pth')\n",
    "            print(f\"Saved checkpoint at epoch {epoch+1}\")\n",
    "            \n",
    "        # Early stopping - Stops training if there's no improvement\n",
    "        early_stopping(val_f1, model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "            break\n",
    "            \n",
    "    return train_losses, val_metrics, learning_rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Data With Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Set device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Create augmentation transform\n",
    "    augmentation = PoseAugmentation(\n",
    "        noise_level=0.02,  # 2% noise relative to the normalized keypoints\n",
    "        drop_edge_prob=0.1,  # 10% probability to drop an edge\n",
    "        invisible_prob=0.1,  # 10% probability to mark a keypoint as invisible\n",
    "        p=0.5  # 50% probability to apply augmentation to a sample\n",
    "    )\n",
    "    \n",
    "    # Load datasets with augmentation\n",
    "    train_dataset, val_dataset = load_dataset(\n",
    "        root_dir=data_dir,\n",
    "        annotation_dir=annotation_dir\n",
    "    )\n",
    "    \n",
    "    # Apply augmentation to training dataset\n",
    "    train_dataset.transform = augmentation\n",
    "    \n",
    "    print(f\"Dataset loaded: {len(train_dataset)} training samples, {len(val_dataset)} validation samples\")\n",
    "    \n",
    "    # Compute class weights for balanced training\n",
    "    train_labels = [data.y.item() for data in train_dataset]\n",
    "    class_weights = compute_class_weight('balanced', classes=np.unique(train_labels), y=train_labels)\n",
    "    class_weights = torch.FloatTensor(class_weights).to(device)\n",
    "    print(f\"Class weights: {class_weights}\")\n",
    "    \n",
    "    # Create data loaders\n",
    "    batch_size = 32\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    \n",
    "    # Create models directory and its subdirectories\n",
    "    os.makedirs('models/original', exist_ok=True)\n",
    "    os.makedirs('models/deep', exist_ok=True)\n",
    "    \n",
    "    print(\"Setup complete!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error during setup: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Original PoseGCN Model (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train the original model for comparison\n",
    "original_model = PoseGCN(num_node_features=2).to(device)\n",
    "original_optimizer = optim.Adam(original_model.parameters(), lr=0.001)\n",
    "\n",
    "print(\"\\n=== Training Original PoseGCN ===\")\n",
    "original_losses, original_metrics, original_lrs = train_and_evaluate(\n",
    "    original_model, train_loader, val_loader, original_optimizer, \n",
    "    num_epochs=500, device=device, class_weights=class_weights,\n",
    "    early_stopping_patience=50, checkpoint_dir='models/original'\n",
    ")\n",
    "\n",
    "# Plot metrics for original model\n",
    "plot_metrics(original_losses, original_metrics, save_path='models/original/original_model_metrics.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Deep PoseGCN Model (Enhanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train the deep model\n",
    "deep_model = DeepPoseGCN(num_node_features=2).to(device)\n",
    "deep_optimizer = optim.Adam(deep_model.parameters(), lr=0.001, weight_decay=1e-4)  # Added weight decay for regularization\n",
    "\n",
    "print(\"\\n=== Training DeepPoseGCN ===\")\n",
    "deep_losses, deep_metrics, deep_lrs = train_and_evaluate(\n",
    "    deep_model, train_loader, val_loader, deep_optimizer, \n",
    "    num_epochs=500, device=device, class_weights=class_weights,\n",
    "    early_stopping_patience=50, checkpoint_dir='models/deep'\n",
    ")\n",
    "\n",
    "# Plot metrics for deep model\n",
    "plot_metrics(deep_losses, deep_metrics, save_path='models/deep/deep_model_metrics.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the best performance of both models\n",
    "print(\"\\n=== Model Comparison ===\")\n",
    "print(f\"Original PoseGCN - Best F1: {max(original_metrics['f1']):.4f}\")\n",
    "print(f\"DeepPoseGCN - Best F1: {max(deep_metrics['f1']):.4f}\")\n",
    "\n",
    "# Add comparison of best precision, recall, and accuracy values\n",
    "print(\"\\n=== Best Precision, Recall, Accuracy Comparison ===\")\n",
    "print(f\"Original PoseGCN - Best Precision: {max(original_metrics['precision']):.4f}\")\n",
    "print(f\"DeepPoseGCN - Best Precision: {max(deep_metrics['precision']):.4f}\")\n",
    "print(\"\\nOriginal PoseGCN - Best Recall: {:.4f}\".format(max(original_metrics['recall'])))\n",
    "print(\"DeepPoseGCN - Best Recall: {:.4f}\".format(max(deep_metrics['recall'])))\n",
    "print(\"\\nOriginal PoseGCN - Best Accuracy: {:.4f}\".format(max(original_metrics['accuracy'])))\n",
    "print(\"DeepPoseGCN - Best Accuracy: {:.4f}\".format(max(deep_metrics['accuracy'])))\n",
    "\n",
    "# Find the epochs with the best metrics for both models\n",
    "original_best_f1_epoch = np.argmax(original_metrics['f1'])\n",
    "deep_best_f1_epoch = np.argmax(deep_metrics['f1'])\n",
    "print(\"\\n=== Best Model Details (Based on F1 Score) ===\")\n",
    "print(f\"Original PoseGCN - Best epoch: {original_best_f1_epoch+1}\")\n",
    "print(f\"  F1: {original_metrics['f1'][original_best_f1_epoch]:.4f}\")\n",
    "print(f\"  Precision: {original_metrics['precision'][original_best_f1_epoch]:.4f}\")\n",
    "print(f\"  Recall: {original_metrics['recall'][original_best_f1_epoch]:.4f}\")\n",
    "print(f\"  Accuracy: {original_metrics['accuracy'][original_best_f1_epoch]:.4f}\")\n",
    "print(f\"\\nDeepPoseGCN - Best epoch: {deep_best_f1_epoch+1}\")\n",
    "print(f\"  F1: {deep_metrics['f1'][deep_best_f1_epoch]:.4f}\")\n",
    "print(f\"  Precision: {deep_metrics['precision'][deep_best_f1_epoch]:.4f}\")\n",
    "print(f\"  Recall: {deep_metrics['recall'][deep_best_f1_epoch]:.4f}\")\n",
    "print(f\"  Accuracy: {deep_metrics['accuracy'][deep_best_f1_epoch]:.4f}\")\n",
    "\n",
    "# Plot comparison of all metrics\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(original_metrics['f1'], 'b-', label='Original PoseGCN')\n",
    "plt.plot(deep_metrics['f1'], 'r-', label='Deep PoseGCN')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.title('F1 Score Comparison')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# Plot precision comparison\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(original_metrics['precision'], 'b-', label='Original PoseGCN')\n",
    "plt.plot(deep_metrics['precision'], 'r-', label='Deep PoseGCN')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision Comparison')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# Plot recall comparison\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(original_metrics['recall'], 'b-', label='Original PoseGCN')\n",
    "plt.plot(deep_metrics['recall'], 'r-', label='Deep PoseGCN')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Recall')\n",
    "plt.title('Recall Comparison')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# Plot accuracy comparison\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(original_metrics['accuracy'], 'b-', label='Original PoseGCN')\n",
    "plt.plot(deep_metrics['accuracy'], 'r-', label='Deep PoseGCN')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy Comparison')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('models/metrics_comparison.png')\n",
    "plt.show()\n",
    "\n",
    "# Create a combined plot of all metrics for each model\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Plot all metrics for original model\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(original_metrics['f1'], 'y-', label='F1')\n",
    "plt.plot(original_metrics['precision'], 'r-', label='Precision')\n",
    "plt.plot(original_metrics['recall'], 'b-', label='Recall')\n",
    "plt.plot(original_metrics['accuracy'], 'g-', label='Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Original PoseGCN Metrics')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# Plot all metrics for deep model\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(deep_metrics['f1'], 'y-', label='F1')\n",
    "plt.plot(deep_metrics['precision'], 'r-', label='Precision')\n",
    "plt.plot(deep_metrics['recall'], 'b-', label='Recall')\n",
    "plt.plot(deep_metrics['accuracy'], 'g-', label='Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Deep PoseGCN Metrics')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('models/all_metrics_by_model.png')\n",
    "plt.show()\n",
    "\n",
    "# Plot learning rate changes\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(original_lrs, 'b-', label='Original PoseGCN')\n",
    "plt.plot(deep_lrs, 'r-', label='Deep PoseGCN')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.title('Learning Rate Adjustments During Training')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.savefig('models/learning_rate_changes.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis and Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best models and analyze their behavior\n",
    "try:\n",
    "    original_checkpoint = torch.load('models/original/model_PoseGCN_best.pth')\n",
    "    deep_checkpoint = torch.load('models/deep/model_DeepPoseGCN_best.pth')\n",
    "    \n",
    "    # Compare convergence speed\n",
    "    original_best_epoch = original_checkpoint['epoch']\n",
    "    deep_best_epoch = deep_checkpoint['epoch']\n",
    "    \n",
    "    print(f\"Original model reached its best performance at epoch {original_best_epoch+1}\")\n",
    "    print(f\"Deep model reached its best performance at epoch {deep_best_epoch+1}\")\n",
    "    \n",
    "    if 'learning_rates' in original_checkpoint and 'learning_rates' in deep_checkpoint:\n",
    "        # Count how many times learning rate was reduced\n",
    "        original_lr_changes = sum(1 for i in range(1, len(original_checkpoint['learning_rates'])) \n",
    "                              if original_checkpoint['learning_rates'][i] != original_checkpoint['learning_rates'][i-1])\n",
    "        deep_lr_changes = sum(1 for i in range(1, len(deep_checkpoint['learning_rates'])) \n",
    "                          if deep_checkpoint['learning_rates'][i] != deep_checkpoint['learning_rates'][i-1])\n",
    "        \n",
    "        print(f\"\\nLearning rate was reduced {original_lr_changes} times for the original model\")\n",
    "        print(f\"Learning rate was reduced {deep_lr_changes} times for the deep model\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Could not analyze checkpoint files: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "In this notebook, we've implemented and compared two models for human pose classification with enhanced training strategies:\n",
    "\n",
    "1. **Original PoseGCN**: A simple 2-layer GCN model\n",
    "2. **DeepPoseGCN**: An enhanced model with 4 layers, residual connections, and batch normalization\n",
    "\n",
    "Both models were trained with the following improvements:\n",
    "- Data augmentation to improve generalization\n",
    "- Class weighting to balance precision and recall\n",
    "- Early stopping to prevent wasted computation\n",
    "- Learning rate scheduling for better convergence\n",
    "- Regular checkpointing during training\n",
    "- Extended training up to 500 epochs (unless early stopping triggered)\n",
    "\n",
    "The results show that the DeepPoseGCN generally achieves better F1 scores, indicating a better balance between precision and recall. The learning rate scheduling helped both models fine-tune their parameters when training plateaued.\n",
    "\n",
    "### Key Insights:\n",
    "\n",
    "1. Early stopping and learning rate scheduling are effective in preventing overfitting while allowing for longer training periods.\n",
    "2. The deeper architecture with residual connections shows better overall performance compared to the simpler model.\n",
    "3. Checkpointing at regular intervals provides a way to analyze model behavior throughout training.\n",
    "\n",
    "### Further Improvements\n",
    "\n",
    "Some potential ways to further enhance performance:\n",
    "1. Try different augmentation strategies\n",
    "2. Experiment with other GNN architectures like GAT (Graph Attention Networks)\n",
    "3. Implement ensemble methods by combining multiple trained models\n",
    "4. Experiment with different optimizers (e.g., AdamW, RMSprop)\n",
    "5. Try more aggressive data augmentation as training progresses"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
